{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2183f50-3d39-4832-af72-42791571713d",
   "metadata": {},
   "source": [
    "# Assignment 2: POTUS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996891f9-c12d-47bb-93f5-2f25cc60709b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 1) President of the United States (Trump vs. Obama)\n",
    "\n",
    "Surely, you're aware that the 45th President of the United States (@POTUS45) was an active user of Twitter, until (permanently) banned on Jan 8, 2021.\n",
    "You can still enjoy his greatness at the [Trump Twitter Archive](https://www.thetrumparchive.com/). We will be using original tweets only, so make sure to remove all retweets.\n",
    "Another fan of Twitter was Barack Obama (@POTUS43 and @POTUS44), who used the platform in a rather professional way.\n",
    "Please also consider the POTUS Tweets of Joe Biden; we will be using those for testing.\n",
    "\n",
    "### Data\n",
    "\n",
    "There are multiple ways to get the data, but the easiest way is to download the files from the `Supplemental Materials` in the `Files` section of our Microsoft Teams group. \n",
    "Another way is to directly use the data from [Trump Twitter Archive](https://www.thetrumparchive.com/), [Obama Kaggle](https://www.kaggle.com/jayrav13/obama-white-house), and [Biden Kaggle](https://www.kaggle.com/rohanrao/joe-biden-tweets).\n",
    "Before you get started, please download the files; you can put them into the data folder.\n",
    "\n",
    "### N-gram Models\n",
    "\n",
    "In this assignment, you will be doing some Twitter-related preprocessing and training n-gram models to be able to distinguish between Tweets of Trump, Obama, and Biden.\n",
    "We will be using [NLTK](https://www.nltk.org), more specifically it's [`lm`](https://www.nltk.org/api/nltk.lm.html) module. \n",
    "Install the NLTK package within your working environment.\n",
    "You can use some of the NLTK functions, but you have to implement the functions for likelihoods and perplexity from scratch.\n",
    "\n",
    "*In this Jupyter Notebook, we will provide the steps to solve this task and give hints via functions & comments. However, code modifications (e.g., function naming, arguments) and implementation of additional helper functions & classes are allowed. The code aims to help you get started.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5ffb0527-90ea-4f0a-ab0c-40817df51dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf666267-390d-402a-aae9-e3588b51c262",
   "metadata": {},
   "source": [
    "### Prepare the Data\n",
    "\n",
    "1.1 Prepare all the Tweets. Since the `lm` modules will work on tokenized data, implement a tokenization method that strips unnecessary tokens but retains special words such as mentions (@...) and hashtags (#...).\n",
    "\n",
    "1.2 Partition into training and test sets; select about 100 tweets each, which we will be testing on later. As with any Machine Learning task, training and test must not overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c2ae5b5d-fccd-4092-af20-d8e8b4a65ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice: ignore retweets \n",
    "\n",
    "def load_trump_tweets(filepath):\n",
    "    \"\"\"Loads all Trump tweets and returns them as a list.\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    ### END YOUR CODE\n",
    "\n",
    "\n",
    "def load_obama_tweets(filepath):\n",
    "    \"\"\"Loads all Obama tweets and returns them as a list.\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "\n",
    "    ### END YOUR CODE\n",
    "    \n",
    "\n",
    "def load_biden_tweets(filepath):\n",
    "    \"\"\"Loads all Biden tweets and returns them as a list.\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f25e8c56-3837-440b-bebe-1916ebede6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice: think about start and end tokens\n",
    "\n",
    "NUM_TEST = 100\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"Tokenizes a single Tweet.\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    ### END YOUR CODE\n",
    "    \n",
    "\n",
    "def split_and_tokenize(data, num_test=NUM_TEST):\n",
    "    \"\"\"Splits and tokenizes the given list of Twitter tweets.\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2598cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trump_tweets = split_and_tokenize(load_trump_tweets(...))\n",
    "# obama_tweets = split_and_tokenize(load_obama_tweets(...))\n",
    "# biden_tweets = split_and_tokenize(load_biden_tweets(...))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c32c33-1a19-42ac-93d0-fcf66fbeaf5f",
   "metadata": {},
   "source": [
    "### Train N-gram Models\n",
    "\n",
    "2.1 Train n-gram models with n = [1, ..., 5] for Obama, Trump, and Biden.\n",
    "\n",
    "2.2 Also train a joint model, that will serve as background model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0828bda0-cef2-428b-a238-7f07f2c25425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_n_gram_models(n, data):\n",
    "    \"\"\"\n",
    "    To predict the first few words of the Tweet, we need the smaller n-grams as\n",
    "    well. This method does calculate all n-grams up to the given n.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    ### END YOUR CODE\n",
    "\n",
    "\n",
    "def get_suggestion(prev, n_gram_model):\n",
    "    \"\"\"\n",
    "    Gets the next random word for the given n_grams.\n",
    "    The size of the previous tokens must be exactly one less than the n-value\n",
    "    of the n-gram, or it will not be able to make a prediction.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    ### END YOUR CODE\n",
    "\n",
    "\n",
    "def get_random_tweet(n, n_gram_models):\n",
    "    \"\"\"Generates a random tweet using the given data set.\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "37e5cc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_gram_models = build_n_gram_models(...)\n",
    "# random_tweet_trump = get_random_tweet(...)\n",
    "# print(random_tweet_trump)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648216bb-a49e-45ff-bb8c-9094c33acc07",
   "metadata": {},
   "source": [
    "### Classify the Tweets\n",
    "\n",
    "3.1 Use the log-ratio method to classify the Tweets for Trump vs. Biden. Trump should be easy to spot; but what about Obama vs. Biden?\n",
    "\n",
    "3.2 Analyze: At what context length (n) does the system perform best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "99dd4ca5-8094-40b0-aa1b-a51268659397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_single_token_log_ratio(prev, token, n_gram_model1, n_gram_model2):\n",
    "    \"\"\"Calculates the log ration of a token for two different n-grams\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    ### END YOUR CODE\n",
    "\n",
    "\n",
    "def classify(n, tokens, n_gram_models1, n_gram_models2):\n",
    "    \"\"\"\n",
    "    Checks which of the two given datasets is more likely for the given Tweet.\n",
    "    If true is returned, the first one is more likely, otherwise the second.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    ### END YOUR CODE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "97d1e9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(n, data1, data2, classify_fn):\n",
    "    \"\"\"\n",
    "    Trains the n-gram models on the train data and validates on the test data.\n",
    "    Uses the implemented classification function to predict the Tweeter.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4f5f88a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# context_length = ...\n",
    "# validate(context_length, trump_tweets, biden_tweets, classify_fn=classify)\n",
    "# validate(context_length, obama_tweets, biden_tweets, classify_fn=classify)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298e1fb7-c67b-4e44-87c7-488e704c5ac1",
   "metadata": {},
   "source": [
    "### Compute Perplexities\n",
    "\n",
    "4.1 Compute (and plot) the perplexities for each of the test tweets and models. Is picking the Model with minimum perplexity a better classifier than in 3.1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9bfe2154-d816-442e-8de8-3b836ab0ffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_with_perplexity(n, tokens, n_gram_models1, n_gram_models2):\n",
    "    \"\"\"\n",
    "    Checks which of the two given datasets is more likely for the given Tweet.\n",
    "    If true is returned, the first one is more likely, otherwise the second.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8b3be177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# context_length = ...\n",
    "# validate(context_length, trump_tweets, biden_tweets, classify_fn=classify_with_perplexity)\n",
    "# validate(context_length, obama_tweets, biden_tweets, classify_fn=classify_with_perplexity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
